{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color: blue; font-size: 34px; font-weight: bold;'> Projeto Proposto \n",
    "</h1>\n",
    "<p style='font-size: 18px; line-height: 2; margin: 0px 0px; text-align: justify; text-indent: 0px;'>    \n",
    "<i> Este projeto baseia-se na criação de um Modelo de Regressão para Previsão do Preço de Imóveis da Califórnia. </i>       \n",
    "</p>  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> Problemática </font>\n",
    "<hr style='border: 2px solid red;'>\n",
    "\n",
    "<p style='font-size: 18px; line-height: 2; margin: 0px 0px; text-align: justify; text-indent: 0px;'>    \n",
    "<i>  Este projeto tem o intuito de ser um Modelo de Machine Learning para prever o preço de imóveis da Califórnia\n",
    "\n",
    "\n",
    "</i> \n",
    "</p>  \n",
    "\n",
    "<p style='font-size: 18px; line-height: 2; margin: 0px 0px; text-align: justify; text-indent: 0px;'>    \n",
    "<i> \n",
    "</i> \n",
    "</p>  \n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/fedesoriano/california-housing-prices-data-extra-features\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> Bibliotecas Utilizadas </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bibliotecas De Manipulação de Dados e Visualização\n",
    "import pandas as pd \n",
    "import builtins as builtins\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from IPython.display import display, Image\n",
    "\n",
    "## Bibliotecas de Modelagem Matemática e Estatística\n",
    "import numpy as np\n",
    "import scipy as sp \n",
    "import scipy.stats as stats\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import normaltest, ttest_ind, ttest_rel, mannwhitneyu, wilcoxon, kruskal, uniform\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "\n",
    "# Bibliotecas de Seleção de Modelos\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate, cross_val_predict\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_regression\n",
    "from feature_engine.selection import DropConstantFeatures, DropCorrelatedFeatures, SmartCorrelatedSelection\n",
    "\n",
    "# Bibliotecas de Pré-Processamento e Pipeline\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Bibliotecas de Modelos de Machine Learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Bibliotecas de Métricas de Machine Learning\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Parâmetros de Otimização\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = '14'\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # Tira os números do formato de Notação Científica\n",
    "np.set_printoptions(suppress=True) # Tira os números do formato de Notação Científica em Numpy Arrays\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # Retira Future Warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> Funções </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Visualização"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plota Barras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_barras(lista_variaveis, hue, df, linhas, colunas, titulo):\n",
    "    if hue != False:\n",
    "        if (linhas == 1) and (colunas == 1):\n",
    "            k = 0\n",
    "            ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', hue = hue)\n",
    "            ax.set_title(f'{titulo}')\n",
    "            ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "            ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "            total = []\n",
    "            for bar in ax.patches:\n",
    "                height = bar.get_height()\n",
    "                total.append(height)\n",
    "            total = builtins.sum(total)\n",
    "            \n",
    "            sizes = []\n",
    "            for bar in ax.patches:\n",
    "                height = bar.get_height()\n",
    "                sizes.append(height)\n",
    "                ax.text(bar.get_x() + bar.get_width()/1.6,\n",
    "                        height,\n",
    "                        f'{builtins.round((height/total)*100, 2)}%',\n",
    "                        ha = 'center',\n",
    "                        fontsize = 12\n",
    "                )\n",
    "            ax.set_ylim(0, builtins.max(sizes)*1.1)\n",
    "            plt.show()\n",
    "        elif linhas == 1:\n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(14, 7), sharey=True)\n",
    "            fig.suptitle(f'{titulo}')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[j], hue = hue)\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = builtins.sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width()/1.6,\n",
    "                                height,\n",
    "                                f'{builtins.round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, builtins.max(sizes)*1.1)\n",
    "                    k = k + 1\n",
    "        elif colunas == 1:\n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(14, 7), sharey=True)\n",
    "            fig.suptitle(f'{titulo}')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[i], hue = hue)\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = builtins.sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width()/1.6,\n",
    "                                height,\n",
    "                                f'{builtins.round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, builtins.max(sizes)*1.1)\n",
    "                    k = k + 1\n",
    "        else: \n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(14, 7), sharey=True)\n",
    "            fig.suptitle(f'{titulo}')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[i, j], hue = hue)\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = builtins.sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width()/1.6,\n",
    "                                height,\n",
    "                                f'{builtins.round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, builtins.max(sizes)*1.1)\n",
    "                    k = k + 1\n",
    "    else:\n",
    "        if (linhas == 1) and (colunas == 1):\n",
    "            k = 0\n",
    "            ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', color='#1FB3E5')\n",
    "            ax.set_title(f'{titulo}')\n",
    "            ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "            ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "            total = []\n",
    "            for bar in ax.patches:\n",
    "                height = bar.get_height()\n",
    "                total.append(height)\n",
    "            total = builtins.sum(total)\n",
    "            \n",
    "            sizes = []\n",
    "            for bar in ax.patches:\n",
    "                height = bar.get_height()\n",
    "                sizes.append(height)\n",
    "                ax.text(bar.get_x() + bar.get_width()/1.6,\n",
    "                        height,\n",
    "                        f'{builtins.round((height/total)*100, 2)}%',\n",
    "                        ha = 'center',\n",
    "                        fontsize = 12\n",
    "                )\n",
    "            ax.set_ylim(0, builtins.max(sizes)*1.1)\n",
    "            plt.show()\n",
    "\n",
    "        elif linhas == 1:\n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(14, 7), sharey=True)\n",
    "            fig.suptitle(f'{titulo}')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[j], color='#1FB3E5')\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = builtins.sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width()/1.6,\n",
    "                                height,\n",
    "                                f'{builtins.round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, builtins.max(sizes)*1.1)\n",
    "                    k = k + 1\n",
    "        elif colunas == 1:\n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(14, 7), sharey=True)\n",
    "            fig.suptitle(f'{titulo}')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[i], color='#1FB3E5')\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = builtins.sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width()/1.6,\n",
    "                                height,\n",
    "                                f'{builtins.round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, builtins.max(sizes)*1.1)\n",
    "                    k = k + 1\n",
    "        else:\n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(14, 7), sharey=True)\n",
    "            fig.suptitle(f'{titulo}')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[i, j], color='#1FB3E5')\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = builtins.sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width()/1.6,\n",
    "                                height,\n",
    "                                f'{builtins.round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, builtins.max(sizes)*1.1)\n",
    "                    k = k + 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plota Histogramas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_histograma(lista_variaveis, df, linhas, colunas, titulo):\n",
    "    if (linhas == 1) and (colunas == 1): \n",
    "        k = 0\n",
    "        mediana = df[lista_variaveis[k]].median()\n",
    "        media = df[lista_variaveis[k]].mean()\n",
    "        plt.figure(figsize = (14, 5))\n",
    "        ax = sns.histplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', bins = 30)\n",
    "        ax.set_title(f'{titulo}')\n",
    "        ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "        ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "        ax.axvline(x = mediana, ymax = 0.75 ,color = '#231F20', linestyle = '-', label = f'mediana = {mediana}')\n",
    "        ax.axvline(x = media, ymax = 0.75,color = '#231F20', linestyle = '--', label = f'media = {media}')\n",
    "        plt.ticklabel_format(style='plain')\n",
    "        plt.legend(loc = 'best')\n",
    "        plt.show()\n",
    "    elif linhas == 1:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 5), sharey = True)\n",
    "        fig.suptitle(f'{titulo}')\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                mediana = df[lista_variaveis[k]].median()\n",
    "                media = df[lista_variaveis[k]].mean().round()\n",
    "                ax = sns.histplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[j], bins = 30)\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                ax.axvline(x = mediana, ymax = 0.75 ,color = '#231F20', linestyle = '-', label = f'mediana = {mediana}')\n",
    "                ax.axvline(x = media, ymax = 0.75,color = '#231F20', linestyle = '--', label = f'media = {media}')\n",
    "                ax.ticklabel_format(style='plain')\n",
    "                ax.legend(loc = 'best')\n",
    "                k = k + 1\n",
    "    elif colunas == 1:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 5), sharey = True)\n",
    "        fig.suptitle(f'{titulo}')\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                mediana = df[lista_variaveis[k]].median()\n",
    "                media = df[lista_variaveis[k]].mean().round()\n",
    "                ax = sns.histplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[i], bins = 30)\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                ax.axvline(x = mediana, ymax = 0.75 ,color = '#231F20', linestyle = '-', label = f'mediana = {mediana}')\n",
    "                ax.axvline(x = media, ymax = 0.75,color = '#231F20', linestyle = '--', label = f'media = {media}')\n",
    "                ax.ticklabel_format(style='plain')\n",
    "                ax.legend(loc = 'best')\n",
    "                k = k + 1\n",
    "    else:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 5), sharey = True)\n",
    "        fig.suptitle(f'{titulo}')\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                mediana = df[lista_variaveis[k]].median()\n",
    "                media = df[lista_variaveis[k]].mean().round()\n",
    "                ax = sns.histplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[i, j], bins = 30)\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                ax.axvline(x = mediana, ymax = 0.75 ,color = '#231F20', linestyle = '-', label = f'mediana = {mediana}')\n",
    "                ax.axvline(x = media, ymax = 0.75,color = '#231F20', linestyle = '--', label = f'media = {media}')\n",
    "                ax.ticklabel_format(style='plain')\n",
    "                ax.legend(loc = 'best')\n",
    "                k = k + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plota Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_boxplot(lista_variaveis, df, linhas, colunas, titulo):\n",
    "    if (linhas == 1) and (colunas == 1): \n",
    "        k = 0\n",
    "        plt.figure(figsize = (14, 12))\n",
    "        ax = sns.boxplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', orient = 'h')\n",
    "        ax.set_title(f'{titulo}')\n",
    "        ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "        ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "        plt.show()\n",
    "    elif linhas == 1:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 12), sharey = True)\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                ax = sns.boxplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[j], orient = 'h')\n",
    "                ax.set_title(f'{titulo}')\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                k = k + 1\n",
    "    elif colunas == 1:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 12), sharey = True)\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                ax = sns.boxplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[i], orient = 'h')\n",
    "                ax.set_title(f'{titulo}')\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                k = k + 1\n",
    "    else:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 12), sharey = True)\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                ax = sns.boxplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[i, j], orient = 'h')\n",
    "                ax.set_title(f'{titulo}')\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                k = k + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plota Dispersão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_dispersao(df, titulo,  x, y, metodo):\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    sns.set(style = 'whitegrid')\n",
    "    corr1 = str(df[[x, y]].corr(method = metodo).iloc[1, 0].round(2))\n",
    "    sns.scatterplot(data = df, x = x, y = y, color = '#1FB3E5', sizes = 1, alpha = 0.50, marker = '.')\n",
    "    plt.text(1, 1, f'Correlacao: {corr1}', fontsize = 12)\n",
    "    plt.title(f'{titulo}', fontsize = 14)\n",
    "    plt.xlabel(f'{x}', fontsize = 14)\n",
    "    plt.ylabel(f'{y}', fontsize = 14)\n",
    "    plt.ticklabel_format(style = 'plain')\n",
    "    plt.grid(True, linestyle=':')\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Estatística"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analisa Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisa_correlacao(metodo, df):\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    heatmap = sns.heatmap(df.corr(method=metodo), vmin=-1, vmax=1, cmap='magma')\n",
    "    heatmap.set_title(f\"Analisando Correlação de {metodo}\")\n",
    "    plt.grid(False)\n",
    "    plt.box(False)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analisa Normalidade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisa_normalidade(amostra1, amostra2, variavel):\n",
    "\n",
    "    normaltest_amostra = normaltest(amostra[variavel])\n",
    "    if normaltest_amostra[1] < 0.05:\n",
    "        print(f'Pelo Teste de Hipótese, A Hipótese Nula de que a variável \"{variavel}\" segue uma Distribuição Normal é REJEITADA!')\n",
    "    else:\n",
    "        print(f'Pelo Teste de Hipótese, A Hipótese Nula de  que a variável \"{variavel}\" segue uma Distribuição Normal é ACEITA')\n",
    "\n",
    "    plt.figure(figsize = (14, 7))\n",
    "    stats.probplot(amostra1[variavel], dist = 'norm', plot = plt)\n",
    "    plt.title(f'Amostra 1', fontsize = 14)\n",
    "    plt.grid(False)\n",
    "    plt.box(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analisa Outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisa_outliers(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IIQ = Q3 - Q1\n",
    "\n",
    "    outlier_inferior = Q1 - 1.5*IIQ \n",
    "    outlier_superior = Q3 + 1.5*IIQ\n",
    "\n",
    "    return outlier_inferior, outlier_superior"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Teste de Hipótese para Duas Amostras Independentes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste_hipotese_duas_amostras_independentes(parametrico, amostra1, amostra2, variavel):\n",
    "    media_amostra_1 = amostra1[variavel].mean()\n",
    "    media_amostra_2 = amostra2[variavel].mean()\n",
    "    mediana_amostra_1 = amostra1[variavel].median()\n",
    "    mediana_amostra_2 = amostra2[variavel].median()\n",
    "\n",
    "    if parametrico == True: \n",
    "        print(f'Média Amostra 1: {media_amostra_1}')\n",
    "        print(f'Média Amostra 2: {media_amostra_2}')\n",
    "        stat, p_value = ztest(amostra1[variavel], amostra2[variavel]) \n",
    "        if p_value > 0.05:\n",
    "            print(f'Pelo Teste de Hipótese Z, não há diferença significativa entre as médias da Amostra 1 e Amostra 2')\n",
    "        else:\n",
    "            print(f'Pelo Teste de Hipótese Z, há diferença significativa entre as médias da Amostra 1 e Amostra 2')\n",
    "    else:\n",
    "        print(f'Mediana Amostra 1: {mediana_amostra_1}')\n",
    "        print(f'Mediana Amostra 2: {mediana_amostra_2}')\n",
    "        stat, p_value = stats.mannwhitneyu(amostra1[variavel], amostra2[variavel]) \n",
    "        if p_value > 0.05:\n",
    "            print(f'Pelo Teste de Hipótese de Mann Whitney, não há diferença significativa entre as medianas da Amostra 1 e Amostra 2')\n",
    "        else:\n",
    "            print(f'Pelo Teste de Hipótese de Mann Whitney, há diferença significativa entre as medianas da Amostra 1 e Amostra 2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Teste de Hipótese para Muitas Amostras Independentes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste_hipotese_muitas_amostras_independentes(amostras, variavel):\n",
    "    medianas = []\n",
    "    \n",
    "    for i, amostra in enumerate(amostras):\n",
    "        mediana_amostra = amostra[variavel].median()\n",
    "        medianas.append(mediana_amostra)\n",
    "        print(f'Mediana Amostra {i+1}: {mediana_amostra}')\n",
    "\n",
    "    stat, p_value = kruskal(*[amostra[variavel] for amostra in amostras])\n",
    "    \n",
    "    if p_value > 0.05:\n",
    "        print(f'Pelo teste de Kruskal-Wallis, não há diferença significativa entre as medianas das amostras')\n",
    "    else:\n",
    "        print(f'Pelo teste de Kruskal-Wallis, há diferença significativa entre as medianas das amostras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove Features de baixa Variância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features_baixa_variancia(target, df, threshold):\n",
    "    target_column = df[target]\n",
    "    features = df.drop(target, axis=1)\n",
    "\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    features_filtered = selector.fit_transform(features)\n",
    "\n",
    "    feature_indices = selector.get_support(indices=True)\n",
    "    selected_features = features.columns[feature_indices]\n",
    "    selected_features = selected_features.append(pd.Index([target]))\n",
    "\n",
    "    return selected_features.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove Features com Base no teste estatístico de interesse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_features_mutual_information(target, df, threshold):\n",
    "    x_train, y_train = separa_feature_target(target, df)\n",
    "\n",
    "    # Calcular a informação mútua entre cada variável e a variável de saída\n",
    "    mutual_info = mutual_info_regression(x_train, y_train, random_state = 42)\n",
    "\n",
    "    # Criar um DataFrame com o nome da feature e sua mutual information\n",
    "    features_selected = pd.DataFrame({'Feature': x_train.columns, 'Mutual Information': mutual_info})\n",
    "    features_selected = features_selected.loc[features_selected['Mutual Information'] > threshold]\n",
    "    features_selected = features_selected.sort_values(by='Mutual Information', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    selected_features = list(features_selected['Feature'])\n",
    "    selected_features.append(target)\n",
    "    \n",
    "    return features_selected, selected_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Métricas ou Avaliação "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Métricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_regressao(regressor, target, y_train, y_predict_train, y_test, y_predict_test, coeficiente_det_train, coeficiente_det_test):\n",
    "    mae_train = mean_absolute_error(y_predict_train, y_train)\n",
    "    mse_train = mean_squared_error(y_predict_train, y_train)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_predict_train, y_train))\n",
    "    metricas_treino = pd.DataFrame({'R2':coeficiente_det_train, 'MAE':mae_train, 'RMSE':rmse_train, 'Etapa':'treino', 'Regressor':regressor}, index = np.arange(1, 2))\n",
    "    \n",
    "    mae_test = mean_absolute_error(y_predict_test, y_test)\n",
    "    mse_test = mean_squared_error(y_predict_test, y_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_predict_test, y_test))\n",
    "    metricas_teste = pd.DataFrame({'R2':coeficiente_det_test, 'MAE':mae_test, 'RMSE':rmse_test, 'Etapa':'teste', 'Regressor':regressor}, index = np.arange(1, 2))\n",
    "    \n",
    "    metricas_finais = pd.concat([metricas_treino, metricas_teste])\n",
    "\n",
    "    return metricas_finais"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validação Cruzada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao_cruzada_classificacao(classificador, x_train, y_train, class_weight, n_splits):\n",
    "\n",
    "    qualitativas_numericas = [column for column in x_train.columns if x_train[column].nunique() <= 5]\n",
    "    discretas = [column for column in x_train.columns if (x_train[column].nunique() > 5) and (x_train[column].nunique() <= 50)]\n",
    "    continuas = [column for column in x_train.columns if x_train[column].nunique() > 50]\n",
    "\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    models = {\n",
    "        'Regressão Logística': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "                ]),\n",
    "            LogisticRegression(random_state=42, class_weight={0:1, 1:class_weight}, solver = 'liblinear')\n",
    "        ),\n",
    "        'Random Forest': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "                ]),\n",
    "            RandomForestClassifier(random_state=42, criterion='log_loss', n_estimators=20, max_depth=4, class_weight={0:1, 1:class_weight})\n",
    "        ),\n",
    "        'XGBoost': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "                ]),\n",
    "            XGBClassifier(random_state=42, n_estimators=20, max_depth=5, learning_rate=0.01, eval_metric='logloss', objective='binary:logistic', scale_pos_weight = class_weight)\n",
    "        )\n",
    "    }\n",
    "\n",
    "    if classificador in models:\n",
    "        model = models[classificador]\n",
    "    else:\n",
    "        print('Utilize Regressão Logística, Random Forest ou XGBoost como opções de Classificadores!')\n",
    "    \n",
    "    scoring = ['accuracy', 'precision', 'recall', 'roc_auc']\n",
    "    scores = cross_validate(model, x_train, y_train, cv=kfold, scoring=scoring, return_train_score=False)\n",
    "    \n",
    "    metricas_finais = pd.DataFrame({\n",
    "        'Acuracia': scores['test_accuracy'].mean(),\n",
    "        'Precisao': scores['test_precision'].mean(),\n",
    "        'Recall': scores['test_recall'].mean(),\n",
    "        'AUC':scores['test_roc_auc'].mean(),\n",
    "        'Etapa': 'validacao_cruzada',\n",
    "        'Classificador': classificador\n",
    "    }, index=[1])\n",
    "    \n",
    "    return metricas_finais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao_cruzada_regressao(regressor, x_train, y_train, n_splits):\n",
    "\n",
    "    qualitativas_numericas = [column for column in x_train.columns if x_train[column].nunique() <= 5]\n",
    "    discretas = [column for column in x_train.columns if (x_train[column].nunique() > 5) and (x_train[column].nunique() <= 50)]\n",
    "    continuas = [column for column in x_train.columns if x_train[column].nunique() > 50]\n",
    "\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    models = {\n",
    "        'Regressão Linear': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "                ]),\n",
    "            LinearRegression()\n",
    "        ),\n",
    "        'KNN Regressor': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "                ]),\n",
    "            KNeighborsRegressor(n_neighbors=5)\n",
    "        ),\n",
    "        'SVR Regressor': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "                ]),\n",
    "            SVR(kernel='linear')\n",
    "        ),\n",
    "        'Random Forest Regressor': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "                ]),\n",
    "            RandomForestRegressor(random_state=42, n_estimators=100, max_depth=5)\n",
    "        ),\n",
    "        'XGBoost Regressor': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "                ]),\n",
    "            XGBRegressor(random_state=42, n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "        )\n",
    "    }\n",
    "\n",
    "    if regressor in models:\n",
    "        model = models[regressor]\n",
    "    else:\n",
    "        print('Utilize Regressão Linear, KNN Regressor, SVR Regressor, Random Forest Regressor ou XGBoost Regressor como opções de Regressor!')\n",
    "    \n",
    "    scoring = ['r2', 'neg_mean_absolute_error', 'neg_mean_squared_error']\n",
    "    scores = cross_validate(model, x_train, y_train, cv=kfold, scoring=scoring, return_train_score=False)\n",
    "    \n",
    "    metricas_finais = pd.DataFrame({\n",
    "        'R2': scores['test_r2'].mean(),\n",
    "        'MAE': -scores['test_neg_mean_absolute_error'].mean(),\n",
    "        'RMSE': np.sqrt(-scores['test_neg_mean_squared_error'].mean()),\n",
    "        'Etapa': 'validacao_cruzada',\n",
    "        'Regressor': regressor\n",
    "    }, index=[1])\n",
    "    \n",
    "    return metricas_finais\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Junção de Matrizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_regressao_modelos_juntos(lista_modelos):\n",
    "    metricas_modelos = pd.concat(lista_modelos).set_index('Regressor')\n",
    "    return metricas_modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Separa entre Features e Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_feature_target(target, dados):\n",
    "    x = dados.drop(target, axis = 1)\n",
    "    y = dados[[target]]\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separa entre Treino e Teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_treino_teste(target, dados, size):\n",
    "    x = dados.drop(target, axis = 1)\n",
    "    y = dados[target]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= size, random_state = 42)\n",
    "\n",
    "    df_train = pd.concat([x_train, y_train], axis = 1)\n",
    "    df_test = pd.concat([x_test, y_test], axis = 1)\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discretização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretiza_variavel(df, variavel_quant, variavel_qualit, bins, labels, right):\n",
    "    df[variavel_qualit] = pd.cut(\n",
    "        df[variavel_quant], \n",
    "        bins= bins, \n",
    "        labels= labels, \n",
    "        right = right\n",
    "    )\n",
    "    df.drop(variavel_quant, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regressor(regressor, x_train, y_train, x_test, y_test):\n",
    "\n",
    "    qualitativas_numericas = [column for column in x_train.columns if x_train[column].nunique() <= 5]\n",
    "    discretas = [column for column in x_train.columns if (x_train[column].nunique() > 5) and (x_train[column].nunique() <= 50)]\n",
    "    continuas = [column for column in x_train.columns if x_train[column].nunique() > 50]\n",
    "\n",
    "    models = {\n",
    "        'Regressão Linear': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "            ]),\n",
    "            LinearRegression()\n",
    "        ),\n",
    "        'KNN Regressor': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "            ]),\n",
    "            KNeighborsRegressor(n_neighbors=5)\n",
    "        ),\n",
    "        'SVR Regressor': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "            ]),\n",
    "            SVR(kernel='linear')\n",
    "        ),\n",
    "        'Random Forest Regressor': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "            ]),\n",
    "            RandomForestRegressor(random_state=42, n_estimators=100, max_depth=10)\n",
    "        ),\n",
    "        'XGBoost Regressor': make_pipeline(\n",
    "            ColumnTransformer([\n",
    "                ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "                ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "                ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "            ]),\n",
    "            XGBRegressor(random_state=42, n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "        )\n",
    "    }\n",
    "\n",
    "    if regressor in models:\n",
    "        model = models[regressor]\n",
    "    else:\n",
    "        print('Utilize Regressão Linear, KNN Regressor, SVR Regressor, Random Forest Regressor ou XGBoost Regressor como opções de Regressor!')\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "\n",
    "    return model, y_pred_train, y_pred_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Algoritmos de Regressão Otimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_otimizado(regressor, x_train, y_train, x_test, y_test):\n",
    "    # Define as colunas categóricas e numéricas\n",
    "    qualitativas_numericas = [column for column in x_train.columns if x_train[column].nunique() <= 5]\n",
    "    discretas = [column for column in x_train.columns if (x_train[column].nunique() > 5) and (x_train[column].nunique() <= 50)]\n",
    "    continuas = [column for column in x_train.columns if x_train[column].nunique() > 50]\n",
    "\n",
    "    # Define o ColumnTransformer\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('qualitativas_numericas', make_pipeline(SimpleImputer(strategy='constant')), qualitativas_numericas),\n",
    "        ('discretas', make_pipeline(SimpleImputer(strategy='median')), discretas),\n",
    "        ('continuas', make_pipeline(SimpleImputer(strategy='median')), continuas)\n",
    "    ])\n",
    "\n",
    "    # Define o modelo de XGBoost com a otimização de hiperparâmetros via BayesSearch\n",
    "    model = make_pipeline(\n",
    "        preprocessor,\n",
    "        BayesSearchCV(\n",
    "            XGBRegressor(random_state=42, objective='reg:squarederror'),\n",
    "            {\n",
    "                'n_estimators': (10, 15, 20, 50), # Número de Árvores construídas\n",
    "                'max_depth': (4, 5, 7), # Profundidade Máxima de cada Árvore\n",
    "                'learning_rate': (0.01, 0.05), # Tamanho do passo utilizado no Método do Gradiente Descendente\n",
    "                'reg_alpha':(0.5, 1), # Valor do Alpha aplicado durante a Regularização Lasso L1 \n",
    "                'reg_lambda':(0.5, 1), # Valor do Lambda aplicado durante a Regularização Ridge L2\n",
    "                'gamma':(0.5, 1), # Valor mínimo permitido para um Nó de Árvore ser aceito. Ajuda a controlar o crescimento das Árvores, evitando divisões insignificantes\n",
    "                'colsample_bytree':(0.5, 1), # Porcentagem de Colunas utilizada para a amostragem aleatória durante a criação das Árvores\n",
    "                'subsample':(0.5, 1), # Porcentagem de Linhas utilizada para a amostragem aleatória durante a criação das Árvores\n",
    "                'colsample_bylevel':(0.5, 1) # Porcentagem de Colunas utilizada para a amostragem aleatória em cada nível das Árvores\n",
    "            },\n",
    "            n_iter=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=5\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Treina o modelo\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "\n",
    "    return model, y_pred_train, y_pred_test, model.named_steps['bayessearchcv'].best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cálculo da Inércia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_method(data, features):\n",
    "    scaler = StandardScaler()\n",
    "    padronizado = scaler.fit_transform(data[features].values.reshape(-1, 1))\n",
    "    wcss = []\n",
    "    \n",
    "    for n_clusters in np.arange(1, 11):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)\n",
    "        kmeans.fit(padronizado)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    plt.plot(np.arange(1, 11), wcss, marker='o', color = 'red')\n",
    "    plt.xlabel('Número de clusters')\n",
    "    plt.ylabel('Soma dos quadrados intra-cluster (WCSS)')\n",
    "    plt.title('Método Elbow')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Algoritmo de Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_esc(data, features, n_clusters):\n",
    "    scaler = StandardScaler()\n",
    "    padronizado = scaler.fit_transform(data[features].values.reshape(-1, 1))\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42, max_iter=300)\n",
    "    kmeans = kmeans.fit(padronizado)\n",
    "    \n",
    "    return kmeans.labels_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 1) Entendimento da Base de Dados </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Descrição das Variáveis\n",
    "\n",
    "- The data pertains to the houses found in a given California district and some summary stats about them based on the 1990 census data. The columns are as follows, their names are pretty self-explanatory:\n",
    "\n",
    "> 1. 'Median House Value' : Valor mediano da casa para famílias dentro de um quarteirão de casas (medido em dólares americanos) [$]\n",
    "\n",
    "> 2. 'Median Income':Renda mediana para famílias dentro de um quarteirão de casas (medida em dezenas de milhares de dólares americanos) [10k$]\n",
    "\n",
    "> 3. 'Median Age': Idade mediana de uma casa dentro de um quarteirão; um número menor é um prédio mais novo [anos]\n",
    "\n",
    "> 4. 'Tot Rooms': Número total de quartos dentro de um quarteirão\n",
    " \n",
    "> 5. 'Tot Bedrooms': Número total de quartos dentro de um quarteirão\n",
    " \n",
    "> 6. 'Population': Número total de pessoas que residem em um quarteirão\n",
    " \n",
    "> 7. 'Households': Número total de domicílios (um grupo de pessoas que residem em uma unidade domiciliar) por quarteirão\n",
    "\n",
    "> 8. 'Distance to coast': Distância ao ponto de costa mais próximo [m]\n",
    " \n",
    "> 9. 'Distance to Los Angeles': Distância ao centro de Los Angeles [m]\n",
    " \n",
    "> 10. 'Distance to San Diego': Distância ao centro de San Diego [m]\n",
    " \n",
    "> 11. 'Distance to San Jose': Distância ao centro de São José [m]\n",
    " \n",
    "> 12. 'Distance to San Francisc': Distância ao centro de São Francisco [m]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodologia\n",
    "\n",
    "> 1. Criar ID para cada uma das casas\n",
    "\n",
    "> 2. Discretizar a distância da costa  e analisar se ela tem influência no preço\n",
    "\n",
    "> 3. Clusterizar em relação as características da casa (median age, total rooms, total bedrooms) --> Analisar o valor, a renda, a quantidade de pessoas e a quantidade de domicílios em cada condição\n",
    "\n",
    "> 4. Clusterizar em relação as distâncias (Los Angeles, San Diego, San Jose, San Francisco) --> Analisar o valor, a renda, a quantidade de pessoas e a quantidade de domicílios em cada condição\n",
    "\n",
    "> 5. Fitar regressões para quebras importantes \n",
    "\n",
    "### Consultas\n",
    "\n",
    "https://www.kaggle.com/code/teesh841/california-housing-prices-regression-analysis\n",
    "\n",
    "https://www.kaggle.com/code/vincentisbear123/predict-california-housing-prices-with-xgboost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Informações Inicais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 12)\n",
      "Median_House_Value          float64\n",
      "Median_Income               float64\n",
      "Median_Age                    int64\n",
      "Tot_Rooms                     int64\n",
      "Tot_Bedrooms                  int64\n",
      "Population                    int64\n",
      "Households                    int64\n",
      "Distance_to_coast           float64\n",
      "Distance_to_LA              float64\n",
      "Distance_to_SanDiego        float64\n",
      "Distance_to_SanJose         float64\n",
      "Distance_to_SanFrancisco    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median_House_Value</th>\n",
       "      <th>Median_Income</th>\n",
       "      <th>Median_Age</th>\n",
       "      <th>Tot_Rooms</th>\n",
       "      <th>Tot_Bedrooms</th>\n",
       "      <th>Population</th>\n",
       "      <th>Households</th>\n",
       "      <th>Distance_to_coast</th>\n",
       "      <th>Distance_to_LA</th>\n",
       "      <th>Distance_to_SanDiego</th>\n",
       "      <th>Distance_to_SanJose</th>\n",
       "      <th>Distance_to_SanFrancisco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452600.00</td>\n",
       "      <td>8.33</td>\n",
       "      <td>41</td>\n",
       "      <td>880</td>\n",
       "      <td>129</td>\n",
       "      <td>322</td>\n",
       "      <td>126</td>\n",
       "      <td>9263.04</td>\n",
       "      <td>556529.16</td>\n",
       "      <td>735501.81</td>\n",
       "      <td>67432.52</td>\n",
       "      <td>21250.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>358500.00</td>\n",
       "      <td>8.30</td>\n",
       "      <td>21</td>\n",
       "      <td>7099</td>\n",
       "      <td>1106</td>\n",
       "      <td>2401</td>\n",
       "      <td>1138</td>\n",
       "      <td>10225.73</td>\n",
       "      <td>554279.85</td>\n",
       "      <td>733236.88</td>\n",
       "      <td>65049.91</td>\n",
       "      <td>20880.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352100.00</td>\n",
       "      <td>7.26</td>\n",
       "      <td>52</td>\n",
       "      <td>1467</td>\n",
       "      <td>190</td>\n",
       "      <td>496</td>\n",
       "      <td>177</td>\n",
       "      <td>8259.09</td>\n",
       "      <td>554610.72</td>\n",
       "      <td>733525.68</td>\n",
       "      <td>64867.29</td>\n",
       "      <td>18811.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341300.00</td>\n",
       "      <td>5.64</td>\n",
       "      <td>52</td>\n",
       "      <td>1274</td>\n",
       "      <td>235</td>\n",
       "      <td>558</td>\n",
       "      <td>219</td>\n",
       "      <td>7768.09</td>\n",
       "      <td>555194.27</td>\n",
       "      <td>734095.29</td>\n",
       "      <td>65287.14</td>\n",
       "      <td>18031.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>342200.00</td>\n",
       "      <td>3.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1627</td>\n",
       "      <td>280</td>\n",
       "      <td>565</td>\n",
       "      <td>259</td>\n",
       "      <td>7768.09</td>\n",
       "      <td>555194.27</td>\n",
       "      <td>734095.29</td>\n",
       "      <td>65287.14</td>\n",
       "      <td>18031.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Median_House_Value  Median_Income  Median_Age  Tot_Rooms  Tot_Bedrooms  \\\n",
       "0           452600.00           8.33          41        880           129   \n",
       "1           358500.00           8.30          21       7099          1106   \n",
       "2           352100.00           7.26          52       1467           190   \n",
       "3           341300.00           5.64          52       1274           235   \n",
       "4           342200.00           3.85          52       1627           280   \n",
       "\n",
       "   Population  Households  Distance_to_coast  Distance_to_LA  \\\n",
       "0         322         126            9263.04       556529.16   \n",
       "1        2401        1138           10225.73       554279.85   \n",
       "2         496         177            8259.09       554610.72   \n",
       "3         558         219            7768.09       555194.27   \n",
       "4         565         259            7768.09       555194.27   \n",
       "\n",
       "   Distance_to_SanDiego  Distance_to_SanJose  Distance_to_SanFrancisco  \n",
       "0             735501.81             67432.52                  21250.21  \n",
       "1             733236.88             65049.91                  20880.60  \n",
       "2             733525.68             64867.29                  18811.49  \n",
       "3             734095.29             65287.14                  18031.05  \n",
       "4             734095.29             65287.14                  18031.05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../04_modelo_previsao_preco_imoveis/data/California_Houses.csv')\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "display(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 2.0 Análise Exploratória </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Separando em Treino e Teste\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = separa_treino_teste('Median_House_Value', df, 0.25)[0]\n",
    "df_test = separa_treino_teste('Median_House_Value', df, 0.25)[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Entendendo Estatísticas Descritivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median_Income</th>\n",
       "      <th>Median_Age</th>\n",
       "      <th>Tot_Rooms</th>\n",
       "      <th>Tot_Bedrooms</th>\n",
       "      <th>Population</th>\n",
       "      <th>Households</th>\n",
       "      <th>Distance_to_coast</th>\n",
       "      <th>Distance_to_LA</th>\n",
       "      <th>Distance_to_SanDiego</th>\n",
       "      <th>Distance_to_SanJose</th>\n",
       "      <th>Distance_to_SanFrancisco</th>\n",
       "      <th>Median_House_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15480.00</td>\n",
       "      <td>15480.00</td>\n",
       "      <td>15480.00</td>\n",
       "      <td>15480.00</td>\n",
       "      <td>15480.00</td>\n",
       "      <td>15480.00</td>\n",
       "      <td>15480.00</td>\n",
       "      <td>15480.00</td>\n",
       "      <td>15480.00</td>\n",
       "      <td>15480.00</td>\n",
       "      <td>15480.00</td>\n",
       "      <td>15480.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.88</td>\n",
       "      <td>28.60</td>\n",
       "      <td>2644.51</td>\n",
       "      <td>539.27</td>\n",
       "      <td>1427.50</td>\n",
       "      <td>500.66</td>\n",
       "      <td>40583.80</td>\n",
       "      <td>270628.24</td>\n",
       "      <td>400156.22</td>\n",
       "      <td>347450.83</td>\n",
       "      <td>384736.13</td>\n",
       "      <td>207034.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.90</td>\n",
       "      <td>12.61</td>\n",
       "      <td>2182.82</td>\n",
       "      <td>421.06</td>\n",
       "      <td>1142.93</td>\n",
       "      <td>382.97</td>\n",
       "      <td>48990.49</td>\n",
       "      <td>247916.22</td>\n",
       "      <td>289229.40</td>\n",
       "      <td>216932.36</td>\n",
       "      <td>249960.62</td>\n",
       "      <td>115516.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>120.68</td>\n",
       "      <td>420.59</td>\n",
       "      <td>484.92</td>\n",
       "      <td>569.45</td>\n",
       "      <td>456.14</td>\n",
       "      <td>14999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>1.07</td>\n",
       "      <td>4.00</td>\n",
       "      <td>151.79</td>\n",
       "      <td>35.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>30.79</td>\n",
       "      <td>1414.76</td>\n",
       "      <td>4720.50</td>\n",
       "      <td>6312.58</td>\n",
       "      <td>6058.32</td>\n",
       "      <td>3059.71</td>\n",
       "      <td>50179.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>1.60</td>\n",
       "      <td>8.00</td>\n",
       "      <td>625.95</td>\n",
       "      <td>136.00</td>\n",
       "      <td>348.95</td>\n",
       "      <td>124.95</td>\n",
       "      <td>3125.92</td>\n",
       "      <td>9889.51</td>\n",
       "      <td>23900.74</td>\n",
       "      <td>25871.97</td>\n",
       "      <td>17999.55</td>\n",
       "      <td>66800.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>1.91</td>\n",
       "      <td>12.00</td>\n",
       "      <td>946.00</td>\n",
       "      <td>198.00</td>\n",
       "      <td>511.00</td>\n",
       "      <td>184.00</td>\n",
       "      <td>4500.13</td>\n",
       "      <td>15317.38</td>\n",
       "      <td>122086.08</td>\n",
       "      <td>53145.94</td>\n",
       "      <td>34307.27</td>\n",
       "      <td>82590.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.57</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1452.00</td>\n",
       "      <td>296.00</td>\n",
       "      <td>788.75</td>\n",
       "      <td>280.00</td>\n",
       "      <td>9084.47</td>\n",
       "      <td>32446.20</td>\n",
       "      <td>159603.33</td>\n",
       "      <td>111852.24</td>\n",
       "      <td>116283.61</td>\n",
       "      <td>119675.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.54</td>\n",
       "      <td>29.00</td>\n",
       "      <td>2131.00</td>\n",
       "      <td>437.00</td>\n",
       "      <td>1167.00</td>\n",
       "      <td>410.50</td>\n",
       "      <td>20567.82</td>\n",
       "      <td>174044.64</td>\n",
       "      <td>222355.77</td>\n",
       "      <td>458493.94</td>\n",
       "      <td>524801.61</td>\n",
       "      <td>179600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.76</td>\n",
       "      <td>37.00</td>\n",
       "      <td>3166.00</td>\n",
       "      <td>648.00</td>\n",
       "      <td>1727.00</td>\n",
       "      <td>607.00</td>\n",
       "      <td>50617.83</td>\n",
       "      <td>528371.26</td>\n",
       "      <td>706946.65</td>\n",
       "      <td>516393.71</td>\n",
       "      <td>584019.51</td>\n",
       "      <td>264700.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>6.16</td>\n",
       "      <td>46.00</td>\n",
       "      <td>4671.30</td>\n",
       "      <td>968.10</td>\n",
       "      <td>2557.00</td>\n",
       "      <td>893.00</td>\n",
       "      <td>118220.89</td>\n",
       "      <td>580659.55</td>\n",
       "      <td>759229.75</td>\n",
       "      <td>575762.34</td>\n",
       "      <td>643789.66</td>\n",
       "      <td>376810.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>10.58</td>\n",
       "      <td>52.00</td>\n",
       "      <td>11191.71</td>\n",
       "      <td>2210.21</td>\n",
       "      <td>5804.63</td>\n",
       "      <td>1985.21</td>\n",
       "      <td>190384.66</td>\n",
       "      <td>836677.38</td>\n",
       "      <td>1014068.02</td>\n",
       "      <td>686223.07</td>\n",
       "      <td>754186.88</td>\n",
       "      <td>500001.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>39320.00</td>\n",
       "      <td>6445.00</td>\n",
       "      <td>35682.00</td>\n",
       "      <td>6082.00</td>\n",
       "      <td>311911.76</td>\n",
       "      <td>1018260.12</td>\n",
       "      <td>1196919.27</td>\n",
       "      <td>836762.68</td>\n",
       "      <td>903627.66</td>\n",
       "      <td>500001.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Median_Income  Median_Age  Tot_Rooms  Tot_Bedrooms  Population  \\\n",
       "count       15480.00    15480.00   15480.00      15480.00    15480.00   \n",
       "mean            3.88       28.60    2644.51        539.27     1427.50   \n",
       "std             1.90       12.61    2182.82        421.06     1142.93   \n",
       "min             0.50        1.00       2.00          1.00        3.00   \n",
       "1%              1.07        4.00     151.79         35.00       86.00   \n",
       "5%              1.60        8.00     625.95        136.00      348.95   \n",
       "10%             1.91       12.00     946.00        198.00      511.00   \n",
       "25%             2.57       18.00    1452.00        296.00      788.75   \n",
       "50%             3.54       29.00    2131.00        437.00     1167.00   \n",
       "75%             4.76       37.00    3166.00        648.00     1727.00   \n",
       "90%             6.16       46.00    4671.30        968.10     2557.00   \n",
       "99%            10.58       52.00   11191.71       2210.21     5804.63   \n",
       "max            15.00       52.00   39320.00       6445.00    35682.00   \n",
       "\n",
       "       Households  Distance_to_coast  Distance_to_LA  Distance_to_SanDiego  \\\n",
       "count    15480.00           15480.00        15480.00              15480.00   \n",
       "mean       500.66           40583.80       270628.24             400156.22   \n",
       "std        382.97           48990.49       247916.22             289229.40   \n",
       "min          1.00             120.68          420.59                484.92   \n",
       "1%          30.79            1414.76         4720.50               6312.58   \n",
       "5%         124.95            3125.92         9889.51              23900.74   \n",
       "10%        184.00            4500.13        15317.38             122086.08   \n",
       "25%        280.00            9084.47        32446.20             159603.33   \n",
       "50%        410.50           20567.82       174044.64             222355.77   \n",
       "75%        607.00           50617.83       528371.26             706946.65   \n",
       "90%        893.00          118220.89       580659.55             759229.75   \n",
       "99%       1985.21          190384.66       836677.38            1014068.02   \n",
       "max       6082.00          311911.76      1018260.12            1196919.27   \n",
       "\n",
       "       Distance_to_SanJose  Distance_to_SanFrancisco  Median_House_Value  \n",
       "count             15480.00                  15480.00            15480.00  \n",
       "mean             347450.83                 384736.13           207034.89  \n",
       "std              216932.36                 249960.62           115516.28  \n",
       "min                 569.45                    456.14            14999.00  \n",
       "1%                 6058.32                   3059.71            50179.00  \n",
       "5%                25871.97                  17999.55            66800.00  \n",
       "10%               53145.94                  34307.27            82590.00  \n",
       "25%              111852.24                 116283.61           119675.00  \n",
       "50%              458493.94                 524801.61           179600.00  \n",
       "75%              516393.71                 584019.51           264700.00  \n",
       "90%              575762.34                 643789.66           376810.00  \n",
       "99%              686223.07                 754186.88           500001.00  \n",
       "max              836762.68                 903627.66           500001.00  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe(percentiles=[0.01, 0.05, 0.1, 0.25, 0.50, 0.75, 0.90, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 3.0 Feature Engineer </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 4.0 Aplicação de Modelos de Machine Learning </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 5.0 Consolidação dos Resultados </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
